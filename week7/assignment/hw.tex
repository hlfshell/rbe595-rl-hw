\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin = 0.8in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{float}


\title{RBE595 - Week 7 Assignment}
\author{Keith Chester}
\date{Due date: February 22, 2023}

\begin{document}
\maketitle

\section*{Problem 1}
\textit{Between DP (Dynamic Programming), MC (Monte-Carlo) and TD (Temporal Difference), which
    one of these algorithms use bootstrapping? Explain. }

\section*{Problem 2}
\textit{We mentioned that the target value for TD is $[R_{t+1} + \gamma V(S_{t+1})]$. What is the target value for Monte-carlo, Q-learning, SARSA and Expected-SARSA.}

\section*{Problem 3}
\textit{What are the similarities of TD and MC?}


\section*{Problem 4}
\textit{Assume that we have two states $x$ and $y$ with the current value of $V(x)=10, V(y)=1$. We run an episode of $\{ x, 3, y, 0, y, 5, T \}$. Whatâ€™s the new estimate of $V(x),V(y)$ using TD (assume step size $\alpha = 0.1$ and discount rate $\gamma = 0.9$)}


\section*{Problem 5}
\textit{Can we consider TD an online (real-time) method and MC an offline method? Why?}


\section*{Problem 6}
\textit{Does Q-learning learn the outcome of exploratory actions? (Refer to the Cliff walking example)}.

\section*{Problem 7}
\textit{What is the advantage of Double Q-learning over Q-learning?}




\end{document}